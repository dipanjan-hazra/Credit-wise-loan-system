import  pandas  as pd
import  numpy  as np 
import seaborn as  sns
import matplotlib.pyplot as plt
from sklearn.model_selection import  train_test_split 


df = pd.read_csv("loan_approval_data.csv")



df.head()
df.info() # 1000 entries and  19 features 
# data  numerical  and  object- catagorical data

df.isnull().sum()





categorical_cols = df.select_dtypes(include=["object"]).columns
numerical_cols = df.select_dtypes(include=["float64"]).columns



numerical_cols
categorical_cols


#filling  with  help  of  SimpleImputer --  for  numerical data
from sklearn.impute import SimpleImputer

num_imp = SimpleImputer(strategy="mean")
df[numerical_cols] = num_imp.fit_transform(df[numerical_cols])


#filling  with  help of  SimpleImputer -- for  categorical data
cat_Imp = SimpleImputer(strategy="most_frequent")
df[categorical_cols] = cat_Imp.fit_transform(df[categorical_cols]);


df.info()
df.isnull().sum()#no null  values  present  now   





# How  balance  is our data 
clases_count = df["Loan_Approved"].value_counts()
plt.pie(clases_count,labels=["No","Yes"],autopct="%1.1f%%")
plt.title("is Loan Approved or not")


# analyze categories 
gender_cnt = df["Gender"].value_counts()
ax =sns.barplot(gender_cnt)
ax.bar_label(ax.containers[0])


# for  educatiion  label 
education_label = df["Education_Level"].value_counts()
ax =sns.barplot(education_label)
ax.bar_label(ax.containers[0])


# for  employer categories 
emp_cat = df["Employer_Category"].value_counts()
ebar = sns.barplot(emp_cat)


# for  Property areas 
property_area = df["Property_Area"].value_counts()
sns.barplot(property_area)


loan_purpose = df["Loan_Purpose"].value_counts()
plt.pie(loan_purpose,labels=loan_purpose.index,autopct="%1.1f%%")
plt.title("loan purpose type")
plt.show()


# analyze income for  applicant

sns.histplot(
    data =df,
    x ="Applicant_Income",
    bins=20
)


# analyze income for  co applicant

sns.histplot(
    data =df,
    x ="Coapplicant_Income",
    bins=20
)


# box plots - for outliers 
sns.boxplot(
    data = df,
    x="Loan_Approved",
    y="Applicant_Income"
) 


fig ,axes =plt.subplots(3,2)
sns.boxplot(ax = axes[0,0],data = df, x="Loan_Approved", y="Applicant_Income") 
sns.boxplot(ax = axes[0,1],data = df, x="Loan_Approved", y="Credit_Score") 
sns.boxplot(ax = axes[1,0],data = df, x="Loan_Approved", y="DTI_Ratio") 
sns.boxplot(ax = axes[1,1],data = df, x="Loan_Approved", y="Savings") 
sns.boxplot(ax = axes[2,0],data = df, x="Loan_Approved", y="Loan_Amount") 
sns.boxplot(ax = axes[2,1],data = df, x="Loan_Approved", y="Age") 


plt.tight_layout()



# Credit  score  and  loan approved  Relation 

sns.histplot(
    data = df, 
    x="Credit_Score",
    hue="Loan_Approved",
    bins= 20,
    multiple="dodge"
)


# Inocme  and  loan approved  Relation 

sns.histplot(
    data = df, 
    x="Applicant_Income",
    hue="Loan_Approved",
    bins= 20,
    multiple="dodge"
)


# remove -- Applicant  Id 
df = df.drop("Applicant_ID",axis =1)





from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

le = LabelEncoder()
df ["Education_Level"] = le.fit_transform(df["Education_Level"])
df ["Loan_Approved"] = le.fit_transform(df["Loan_Approved"])


cols = ["Employment_Status","Marital_Status","Loan_Purpose","Property_Area","Gender","Employer_Category"]

Ohe = OneHotEncoder(drop="first",sparse_output=False,handle_unknown ="ignore")

encoded =Ohe.fit_transform(df[cols])

encoded_df = pd.DataFrame(encoded,columns = Ohe.get_feature_names_out(cols),index=df.index)

# concate  encoded  feature to  df 
df  = pd.concat([df.drop(columns = cols),encoded_df],axis=1)


df.sample(10) #  now  data  look  like  this 
df.info()





num_cols = df.select_dtypes(include="number")
corr_matrix = num_cols.corr()
plt.figure(figsize=(15,8))
sns.heatmap(
    corr_matrix,
    annot =True,
    fmt=".2f",
    cmap ="coolwarm"
) #use  it  for  check  linear  relation 


num_cols.corr()["Loan_Approved"].sort_values(ascending = False)





x = df.drop("Loan_Approved",axis =1)
y=df["Loan_Approved"]


x_train,x_test,y_train,y_test = train_test_split(
    x,y ,test_size=0.2,random_state = 42)


x_test.head()


# feature  scaling 

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)


x_test_scaled





# Logistic regression 
from  sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

log_model = LogisticRegression()
log_model.fit(x_train_scaled,y_train)

log_predict=log_model.predict(x_test_scaled)

# Evaluation - 
# decission  will be  based  on precision 
print("For Logistic regression -----")
print("precision scroe = ", precision_score(y_test,log_predict))
print("recall scroe = ", recall_score(y_test,log_predict))
print("f1 scroe = ", f1_score(y_test,log_predict))
print("Accuracy scroe = ", accuracy_score(y_test,log_predict))
print("confusion matrix = \n", confusion_matrix(y_test,log_predict))



# KNN - Classifier
from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(x_train_scaled,y_train)

y_predict = knn_model.predict(x_test_scaled)

# Evaluation - 
# decission  will be  based  on precision 
print("For knn classifier  -----")
print("precision scroe = ", precision_score(y_test,y_predict))
print("recall scroe = ", recall_score(y_test,y_predict))
print("f1 scroe = ", f1_score(y_test,y_predict))
print("Accuracy scroe = ", accuracy_score(y_test,y_predict))
print("confusion matrix = \n", confusion_matrix(y_test,y_predict))


from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(x_train_scaled,y_train)

y_predict = nb_model.predict(x_test_scaled)

# Evaluation - 
# decission  will be  based  on precision 
print("For Nb regression -----")
print("precision scroe = ", precision_score(y_test,y_predict))
print("recall scroe = ", recall_score(y_test,y_predict))
print("f1 scroe = ", f1_score(y_test,y_predict))
print("Accuracy scroe = ", accuracy_score(y_test,y_predict))
print("confusion matrix = \n", confusion_matrix(y_test,y_predict))








# 2  feature  from  correlation  heatmap stand  out - 1 . DTI ratio and  2. Credit score 
#  we increase  the  imact for  this  2  feature 

df ["DTI_Ratio_sq"] = df["DTI_Ratio" ] ** 2
df ["Credit_Score_sq"] = df["Credit_Score" ] ** 2

# not  skewed data  for  lern  this i  implement  compression  with log1p

#df["Applicant_Income_log"] = np.log1p(df["Applicant_Income"]) # only for  skeweed data 

x = df.drop(columns = ["Loan_Approved","Credit_Score","DTI_Ratio",])
y = df["Loan_Approved"]



x.head()


#train-test-split
x_train,x_test,y_train,y_test = train_test_split(
    x,y,test_size=0.2,random_state=42
)



#feature scaling 

x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

x_train_scaled
x_test_scaled


# Logistic regression
from  sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

log_model = LogisticRegression()
log_model.fit(x_train_scaled,y_train)

log_predict=log_model.predict(x_test_scaled)

# Evaluation - 
# decission  will be  based  on precision 
print("For Logistic regression -----")
print("precision scroe = ", precision_score(y_test,log_predict))
print("recall scroe = ", recall_score(y_test,log_predict))
print("f1 scroe = ", f1_score(y_test,log_predict))
print("Accuracy scroe = ", accuracy_score(y_test,log_predict))
print("confusion matrix = \n", confusion_matrix(y_test,log_predict))



from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(x_train_scaled,y_train)

y_predict = knn_model.predict(x_test_scaled)

# Evaluation - 
# decission  will be  based  on precision 
print("For knn classifier  -----")
print("precision scroe = ", precision_score(y_test,y_predict))
print("recall scroe = ", recall_score(y_test,y_predict))
print("f1 scroe = ", f1_score(y_test,y_predict))
print("Accuracy scroe = ", accuracy_score(y_test,y_predict))
print("confusion matrix = \n", confusion_matrix(y_test,y_predict))


from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(x_train_scaled,y_train)

y_predict = nb_model.predict(x_test_scaled)

# Evaluation - 
# decission  will be  based  on precision 
print("For Nb regression -----")
print("precision scroe = ", precision_score(y_test,y_predict))
print("recall scroe = ", recall_score(y_test,y_predict))
print("f1 scroe = ", f1_score(y_test,y_predict))
print("Accuracy scroe = ", accuracy_score(y_test,y_predict))
print("confusion matrix = \n", confusion_matrix(y_test,y_predict))
